{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent with Minibatch and Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MomentumGradientDescent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate=0.001,\n",
    "        momentum=0.9,\n",
    "        max_iters=1e4,\n",
    "        epsilon=1e-8,\n",
    "        batch_size=32,\n",
    "        record_history=False,\n",
    "    ):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.max_iters = max_iters\n",
    "        self.record_history = record_history\n",
    "        self.epsilon = epsilon\n",
    "        self.batch_size = batch_size\n",
    "        self.prev_delta_w = None\n",
    "        if record_history:\n",
    "            # to store the weight history for visualization\n",
    "            self.w_history = []\n",
    "\n",
    "    def run(self, gradient_fn, x, y, w):\n",
    "        grad = np.inf\n",
    "        t = 1\n",
    "        N, D = x.shape\n",
    "        self.prev_delta_w = np.zeros(w.shape)\n",
    "        while np.linalg.norm(grad) > self.epsilon and t < self.max_iters:\n",
    "            for i in range(0, N, self.batch_size):\n",
    "                if x.ndim == 1:\n",
    "                    batch_x = x[i:i + self.batch_size]\n",
    "                else:\n",
    "                    batch_x = x[i:i + self.batch_size, :]\n",
    "\n",
    "                if y.ndim == 1:\n",
    "                    batch_y = y[i:i + self.batch_size]\n",
    "                else:\n",
    "                    batch_y = y[i:i + self.batch_size, :]\n",
    "\n",
    "                # compute the gradient with present weight\n",
    "                grad = gradient_fn(batch_x, batch_y, w)\n",
    "                delta_w = self.get_delta_w(grad)\n",
    "\n",
    "                # weight update step\n",
    "                w = w - self.learning_rate * delta_w\n",
    "                if self.record_history:\n",
    "                    self.w_history.append(w)\n",
    "            t += 1\n",
    "        return w\n",
    "\n",
    "    def get_delta_w(self, grad):\n",
    "        beta = self.momentum\n",
    "        delta_w = beta * self.prev_delta_w + (1 - beta) * grad\n",
    "        self.prev_delta_w = delta_w\n",
    "\n",
    "        return delta_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression\n",
    "\n",
    "Below is our implementation of the Softmax Regression model. Class labels and predictions are one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from the given Colab code\n",
    "logistic = lambda z: 1./ (1 + np.exp(-z))  \n",
    "\n",
    "class SoftmaxRegression:\n",
    "\n",
    "    def __init__(self, add_bias=True):\n",
    "        self.add_bias = add_bias\n",
    "        pass\n",
    "            \n",
    "    def fit(self, x, y, C, optimizer):\n",
    "        if x.ndim == 1:\n",
    "            x = x[:, None]\n",
    "        if self.add_bias:\n",
    "            N = x.shape[0]\n",
    "            x = np.column_stack([x,np.ones(N)])\n",
    "        N,D = x.shape\n",
    "        \n",
    "        def to_onehot(a):\n",
    "            return np.eye(C)[a]\n",
    "        \n",
    "        def gradient(x, y, w):\n",
    "            N, D = x.shape\n",
    "            # yh: N x C\n",
    "            yh = self.softmax(np.dot(x, w))\n",
    "            # both are N x C\n",
    "            yh = to_onehot(self.to_classlabel(yh))\n",
    "            y = to_onehot(y)\n",
    "            \n",
    "            grad = np.dot(x.T, yh - y) / N\n",
    "            return grad\n",
    "        \n",
    "        # initialize all weights to 0\n",
    "        w0 = np.zeros((D,C)) \n",
    "        # run the optimizer to get the optimal weights\n",
    "        self.w = optimizer.run(gradient, x, y, w0) \n",
    "        return self\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        # to prevent overflow/underflow\n",
    "        z = z - np.max(z, axis=-1, keepdims=True)\n",
    "        return (np.exp(z.T) / np.sum(np.exp(z), axis=1)).T\n",
    "\n",
    "    def to_classlabel(self, z):\n",
    "        return z.argmax(axis=1)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.add_bias:\n",
    "            x = np.column_stack([x,np.ones(N)])\n",
    "        # convert from 1D to 2D\n",
    "        x = np.reshape(x, (1, -1))\n",
    "        yh = self.softmax(np.dot(x, self.w))\n",
    "        return self.to_classlabel(yh)[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of Model\n",
    "\n",
    "Throughout the code below, validation is performed using 5-fold cross-validation. Here we define some helper methods which are used in the following sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def k_fold_splitter(fold, dataset):\n",
    "    \"\"\"\n",
    "    Returns 2 datasets (training and validation)\n",
    "    \"\"\"\n",
    "    start = math.floor(fold*(dataset.shape[0]/5))\n",
    "    end = math.floor((fold+1)*(dataset.shape[0]/5))\n",
    "\n",
    "    training = np.delete(dataset, slice(start, end-1), axis=0)\n",
    "    validation = dataset[start:end-1]\n",
    "\n",
    "    return training, validation\n",
    "\n",
    "def calculate_model_accuracy(x, y, C, learning_rate, momentum, batch_size):\n",
    "    \"\"\"\n",
    "    Helper method to calculate the accuracy of our implemented Softmax\n",
    "    Regression model for a given set of inputs, labels, and hyper-parameters\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    # do 5-fold cross-validation\n",
    "    for fold_num in range(5):\n",
    "        train_data, validation_data = k_fold_splitter(fold_num, x)\n",
    "        train_labels, validation_labels = k_fold_splitter(fold_num, y)\n",
    "\n",
    "        optimizer = MomentumGradientDescent(\n",
    "            learning_rate=learning_rate, \n",
    "            momentum=momentum, \n",
    "            batch_size=batch_size, \n",
    "            max_iters=10000,\n",
    "        )\n",
    "        model = SoftmaxRegression(add_bias=False)\n",
    "        model.fit(train_data, train_labels, C, optimizer)\n",
    "\n",
    "        num_misclassified = 0\n",
    "        # calculate the accuracy\n",
    "        for i in range(len(validation_data)):\n",
    "            prediction = model.predict(validation_data[i, :])\n",
    "            if prediction != validation_labels[i]:\n",
    "                num_misclassified += 1\n",
    "\n",
    "        misclassification_rate = num_misclassified / len(validation_labels)\n",
    "        accuracies.append(1 - misclassification_rate)\n",
    "        \n",
    "    return np.average(accuracies)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search to Find Good Hyper-Parameters\n",
    "\n",
    "### Digits Dataset\n",
    "\n",
    "First we do a grid search to find a good set of hyper-parameters (learning rate, momentum, batch size). This will give us a reference point for the model's performance which we can compare to as we change individual hyper-parameters. These parameters are not optimal since our grid search does not try an extensive set of combinations, but they are at least a good starting point. We kept the number of combinations on the smaller side since each loop iteration is fairly expensive in terms of computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9179642395854406, 0.9213224195079441, 0.9218873033410622 [BATCH], 0.9224490748665598 [BATCH], \n",
      "\n",
      "Best Accuracy: 0.9224490748665598\n",
      "Best Learning Rate: 0.0001\n",
      "Best Momentum: 0.549\n",
      "Best Batch Size: 321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "x, y = digits.data, digits.target\n",
    "\n",
    "C = 10\n",
    "max_accuracy = 0\n",
    "best_learning_rate = 0\n",
    "best_momentum = 0\n",
    "best_batch_size = x.shape[0]\n",
    "\n",
    "# grid search to find good hyper-parameters\n",
    "for learning_rate in np.linspace(0.0001, 0.2, 21):\n",
    "    for momentum in np.linspace(0.5, 0.99, 11):\n",
    "        accuracy = calculate_model_accuracy(x, y, C, learning_rate, momentum, x.shape[0])\n",
    "        if accuracy > max_accuracy:\n",
    "            print(accuracy, end = ', ')\n",
    "            max_accuracy = accuracy\n",
    "            best_learning_rate = learning_rate\n",
    "            best_momentum = momentum\n",
    "            \n",
    "for batch_size in range(1, x.shape[0], 64):\n",
    "    accuracy = calculate_model_accuracy(x, y, C, best_learning_rate, best_momentum, batch_size)\n",
    "    if accuracy > max_accuracy:\n",
    "        print(accuracy, end = ' [BATCH], ')\n",
    "        max_accuracy = accuracy\n",
    "        best_batch_size = batch_size\n",
    "            \n",
    "print(\"\\n\\nBest Accuracy: {}\".format(max_accuracy))  \n",
    "print(\"Best Learning Rate: {}\".format(best_learning_rate))  \n",
    "print(\"Best Momentum: {}\".format(best_momentum))  \n",
    "print(\"Best Batch Size: {}\".format(best_batch_size))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Dataset\n",
    "\n",
    "Similar to above, we first do a grid search to find a good set of hyper-parameters as a reference point for the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6726050420168067, 0.712436974789916, 0.9124369747899159, 0.9188235294117648, \n",
      "\n",
      "Best Accuracy: 0.9188235294117648\n",
      "Best Learning Rate: 0.0001\n",
      "Best Momentum: 0.892\n",
      "Best Batch Size: 178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "x, y = wine.data, wine.target\n",
    "\n",
    "C = 3\n",
    "max_accuracy = 0\n",
    "best_learning_rate = 0\n",
    "best_momentum = 0\n",
    "best_batch_size = x.shape[0]\n",
    "\n",
    "# grid search to find good hyper-parameters\n",
    "for learning_rate in np.linspace(0.0001, 0.2, 21):\n",
    "    for momentum in np.linspace(0.5, 0.99, 11):\n",
    "        accuracy = calculate_model_accuracy(x, y, C, learning_rate, momentum, x.shape[0])\n",
    "        if accuracy > max_accuracy:\n",
    "            print(accuracy, end=', ')\n",
    "            max_accuracy = accuracy\n",
    "            best_learning_rate = learning_rate\n",
    "            best_momentum = momentum\n",
    "            \n",
    "# use an increment of 16 instead of 64 since this dataset is much smaller\n",
    "for batch_size in range(1, x.shape[0], 16):\n",
    "    accuracy = calculate_model_accuracy(x, y, C, best_learning_rate, best_momentum, batch_size)\n",
    "    if accuracy > max_accuracy:\n",
    "        print(accuracy, end=' [BATCH], ')\n",
    "        max_accuracy = accuracy\n",
    "        best_batch_size = batch_size\n",
    "            \n",
    "print(\"\\n\\nBest Accuracy: {}\".format(max_accuracy))\n",
    "print(\"Best Learning Rate: {}\".format(best_learning_rate))\n",
    "print(\"Best Momentum: {}\".format(best_momentum))\n",
    "print(\"Best Batch Size: {}\".format(best_batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis - Varying Individual Hyper-Parameters\n",
    "\n",
    "Now that we have a good set of hyper-parameters, we can observe how the accuracy of the Softmax Regression model changes as the value of one hyper-parameter is varied.\n",
    "\n",
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_wine\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = load_digits()\n",
    "x, y = digits.data, digits.target\n",
    "\n",
    "C = 10\n",
    "digits_accuracies = []\n",
    "momentums = np.linspace(0, 0.99, 50)\n",
    "\n",
    "for momentum in momentums:\n",
    "    # using the hyper-parameter values obtained from grid search\n",
    "    accuracy = calculate_model_accuracy(x, y, C, 0.0001, momentum, 321)\n",
    "    digits_accuracies.append(accuracy)\n",
    "\n",
    "# plot for accuracy vs. momentum on digits dataset\n",
    "plt.plot(momentums, digits_accuracies, '.')\n",
    "plt.title('Accuracy vs. Momentum (Digits Dataset)')\n",
    "plt.xlabel('momentum')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "x, y = wine.data, wine.target\n",
    "\n",
    "C = 3\n",
    "wine_accuracies = []\n",
    "momentums = np.linspace(0, 0.99, 50)\n",
    "\n",
    "for momentum in momentums:\n",
    "    # using the hyper-parameter values obtained from grid search\n",
    "    accuracy = calculate_model_accuracy(x, y, C, 0.0001, momentum, x.shape[0])\n",
    "    wine_accuracies.append(accuracy)\n",
    "\n",
    "# plot for accuracy vs. momentum on wine dataset\n",
    "plt.plot(momentums, wine_accuracies, '.')\n",
    "plt.title('Accuracy vs. Momentum (Wine Dataset)')\n",
    "plt.xlabel('momentum')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Against Other Classifiers\n",
    "\n",
    "Now we can compare our model to an off-the-shelf classifier to see how the performance compares on the digits dataset. We will be comparing against the Ridge Regression and Logistic Regression models from SciKit Learn.\n",
    "\n",
    "### Digits Dataset Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Regression Accuracy: 0.9224490748665598\n",
      "Ridge Regression (SKLearn) Accuracy: 0.8900795194597034\n",
      "Logistic Regression (SKLearn) Accuracy: 0.9179657957392509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "digits = load_digits()\n",
    "x, y = digits.data, digits.target\n",
    "\n",
    "C = 10\n",
    "# using the hyper-parameters obtained from grid search\n",
    "softmax_accuracy = calculate_model_accuracy(x, y, C, 0.0001, 0.549, 321)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model_accuracies = []\n",
    "for fold_num in range(5):\n",
    "    train_data, validation_data = k_fold_splitter(fold_num, x)\n",
    "    train_labels, validation_labels = k_fold_splitter(fold_num, y)\n",
    "\n",
    "    ridge_model = RidgeClassifier(max_iter=10000)\n",
    "    ridge_model.fit(train_data, train_labels)\n",
    "\n",
    "    ridge_model_accuracies.append(ridge_model.score(validation_data, validation_labels))\n",
    "    \n",
    "# Logistic Regression\n",
    "logistic_model_accuracies = []\n",
    "for fold_num in range(5):\n",
    "    train_data, validation_data = k_fold_splitter(fold_num, x)\n",
    "    train_labels, validation_labels = k_fold_splitter(fold_num, y)\n",
    "\n",
    "    logistic_model = LogisticRegression(multi_class=\"multinomial\", max_iter=10000)\n",
    "    logistic_model.fit(train_data, train_labels)\n",
    "\n",
    "    logistic_model_accuracies.append(logistic_model.score(validation_data, validation_labels))\n",
    "\n",
    "print(\"Softmax Regression Accuracy: {}\".format(softmax_accuracy))\n",
    "print(\"Ridge Regression (SKLearn) Accuracy: {}\".format(np.average(ridge_model_accuracies)))\n",
    "print(\"Logistic Regression (SKLearn) Accuracy: {}\".format(np.average(logistic_model_accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Dataset Comparison\n",
    "\n",
    "We can do the same comparison on the wine dataset. This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Regression Accuracy: 0.9188235294117648\n",
      "Ridge Regression (SKLearn) Accuracy: 0.9478991596638655\n",
      "Logistic Regression (SKLearn) Accuracy: 0.9359663865546219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "wine = load_wine()\n",
    "x, y = wine.data, wine.target\n",
    "\n",
    "C = 3\n",
    "# using the hyper-parameters obtained from grid search\n",
    "softmax_accuracy = calculate_model_accuracy(x, y, C, 0.0001, 0.892, 178)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model_accuracies = []\n",
    "for fold_num in range(5):\n",
    "    train_data, validation_data = k_fold_splitter(fold_num, x)\n",
    "    train_labels, validation_labels = k_fold_splitter(fold_num, y)\n",
    "\n",
    "    ridge_model = RidgeClassifier(max_iter=10000)\n",
    "    ridge_model.fit(train_data, train_labels)\n",
    "\n",
    "    ridge_model_accuracies.append(ridge_model.score(validation_data, validation_labels))\n",
    "    \n",
    "# Logistic Regression\n",
    "logistic_model_accuracies = []\n",
    "for fold_num in range(5):\n",
    "    train_data, validation_data = k_fold_splitter(fold_num, x)\n",
    "    train_labels, validation_labels = k_fold_splitter(fold_num, y)\n",
    "\n",
    "    logistic_model = LogisticRegression(multi_class=\"multinomial\", max_iter=10000)\n",
    "    logistic_model.fit(train_data, train_labels)\n",
    "\n",
    "    logistic_model_accuracies.append(logistic_model.score(validation_data, validation_labels))\n",
    "\n",
    "print(\"Softmax Regression Accuracy: {}\".format(softmax_accuracy))\n",
    "print(\"Ridge Regression (SKLearn) Accuracy: {}\".format(np.average(ridge_model_accuracies)))\n",
    "print(\"Logistic Regression (SKLearn) Accuracy: {}\".format(np.average(logistic_model_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
